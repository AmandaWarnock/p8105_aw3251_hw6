---
title: "Homework 6"
author: Amanda Warnock
output: github_document
---

This is my solution to HW6.

```{r}
library(tidyverse)
library(modelr)
library(mgcv)
```


## Problem 1

```{r}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest" ~0,
      disposition == "Closed by arrest" ~ 1)
    ) %>% 
  filter(
    city_state !="Tulsa, AL",
    victim_race %in% c("White", "Black")) %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
  
```

```{r}
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_race + victim_sex,
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits=3)
```
^remember that you need to exponentiate the estimates to be able to compare them to 1

try across cities
```{r}
model_results_df = 
homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x,
    family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI"))
```

```{r}
model_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
theme(axis.text.x = element_text(angle = 90))
```

## Problem 2

Loading data.

```{r}
bw_df =
  read.csv("data/birthweight.csv") %>% 
  janitor::clean_names()
```

Cleaning data.


```{r}
bw_df = 
bw_df %>% 
  mutate(
    babysex = as.character(babysex),
    babysex = case_when(
      babysex == 1 ~ "Male",
      babysex == 2 ~ "Female"),
    frace = as.character(frace),
    frace = case_when(
      frace == 1 ~ "White",
      frace == 2 ~ "Black",
      frace == 3 ~ "Asian",
      frace == 4 ~ "Puerto Rican",
      frace == 8 ~ "Other",
      frace == 9 ~ "Unknown"),
    gaweeks = as.double(gaweeks),
    malform = as.character(malform),
    malform = case_when(
      malform == 0 ~ "absent",
      malform == 1 ~ "present"),
    mrace = as.character(mrace),
    mrace = case_when(
      mrace == 1 ~ "White",
      mrace == 2 ~ "Black",
      mrace == 3 ~ "Asian",
      mrace == 4 ~ "Puerto Rican",
      mrace == 8 ~ "Other"),
    ppbmi = as.double(ppbmi),
    smoken = as.double(smoken)
    )
```

Income, smoking, and the age of the mother have all been found to be associated with birthweight. Generally, it can be hypothesized that have a lower income, more cigarettes per day, and an older age may result in lower birthweight. I'm curious to look into these factors to see how much of an impact they appear to have on birthweight. 

Here, I set up the linear regression and clean the output.

```{r}
fit = lm(bwt ~ fincome + smoken + momage, data = bw_df)
summary(fit)

fit_table = 
fit %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  mutate(
    term = str_replace(term, "^fincome", "Family monthly income in hundreds"),
    term = str_replace(term, "^smoken", "Av. cigarettes per day during pregnancy"),
    term = str_replace (term, "^momage", "Age of mom at delivery")) %>% 
  knitr::kable()

fit_table
```

Exploratory analysis.

```{r}
fincome_resid = 
bw_df %>% 
  modelr::add_residuals(fit) %>% 
  ggplot(aes(x =  fincome, y = resid)) + geom_violin()

fincome_pred = 
  bw_df %>% 
  modelr::add_predictions(fit) %>% 
  ggplot(aes(x = fincome, y  = pred)) + geom_violin()
```

```{r}
smoken_resid = 
bw_df %>% 
  modelr::add_residuals(fit) %>% 
  ggplot(aes(x = smoken, y = resid)) + geom_violin()

smoken_pred = 
  bw_df %>% 
  modelr::add_predictions(fit) %>% 
  ggplot(aes(x = smoken, y = pred)) + geom_violin()
```

```{r}
momage_resid = 
  bw_df %>% 
  modelr::add_residuals(fit) %>% 
  ggplot(aes(x = momage, y = resid)) + geom_violin()

momage_pred = 
  bw_df %>% 
  modelr::add_predictions(fit) %>% 
  ggplot(aes(x = momage, y = pred)) + geom_violin()
```

Plot of residuals. 

```{r}
resid_pred = 
bw_df %>% 
  modelr::add_residuals(fit) %>% 
  modelr::add_predictions(fit)  %>% 
  ggplot(aes(x = resid, y = pred)) + geom_point()

resid_pred
```

Residuals tend to cluster around 0 and predictions tend to cluster around 3100. 

Compare to other models. 

```{r}
fit2 = lm(bwt ~ blength + gaweeks, data = bw_df)
summary(fit2)

fit2_resid_pred = 
  bw_df %>% 
  modelr::add_residuals(fit2) %>% 
  modelr::add_predictions(fit2) %>% 
  ggplot(aes(x = resid, y = pred)) + geom_point()

fit2_resid_pred
```

While these resdiuals also cluster around 0 and the predictions cluster around 3000, there are some major outliers.  

```{r}
fit3 = lm(bwt ~ bhead + blength + babysex, data = bw_df)
summary(fit3)

fit3_resid_pred = 
  bw_df  %>% 
  modelr::add_residuals(fit3) %>% 
  modelr::add_predictions(fit3) %>% 
  ggplot(aes(x = resid, y = pred)) + geom_point()

fit3_resid_pred
```

Overall clustering is similar, but there are also multiple major outliers. 

Comparing via cross-validation.

